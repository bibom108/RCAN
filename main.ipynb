{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import utility\n",
    "import data\n",
    "import model\n",
    "import loss\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import template\n",
    "\n",
    "parser = argparse.ArgumentParser(description='EDSR and MDSR')\n",
    "\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help='Enables debug mode')\n",
    "parser.add_argument('--template', default='.',\n",
    "                    help='You can set various templates in option.py')\n",
    "\n",
    "# Hardware specifications\n",
    "parser.add_argument('--n_threads', type=int, default=3,\n",
    "                    help='number of threads for data loading')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use cpu only')\n",
    "parser.add_argument('--n_GPUs', type=int, default=4,\n",
    "                    help='number of GPUs')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed')\n",
    "\n",
    "# Data specifications\n",
    "parser.add_argument('--dir_train', type=str, default='../input/df2k-ost/train/DIV2K/DIV2K_train_HR',\n",
    "                    help='train dataset directory')\n",
    "parser.add_argument('--dir_test', type=str, default='../input/df2k-ost/test/DIV2K_valid',\n",
    "                    help='test dataset directory')\n",
    "# parser.add_argument('--dir_demo', type=str, default='../test',\n",
    "#                     help='demo image directory')\n",
    "# parser.add_argument('--data_train', type=str, default='DIV2K',\n",
    "#                     help='train dataset name')\n",
    "# parser.add_argument('--data_test', type=str, default='DIV2K',\n",
    "#                     help='test dataset name')\n",
    "parser.add_argument('--benchmark_noise', action='store_true',\n",
    "                    help='use noisy benchmark sets')\n",
    "parser.add_argument('--n_train', type=int, default=800,\n",
    "                    help='number of training set')\n",
    "parser.add_argument('--n_val', type=int, default=5,\n",
    "                    help='number of validation set')\n",
    "parser.add_argument('--offset_val', type=int, default=800,\n",
    "                    help='validation index offest')\n",
    "parser.add_argument('--ext', type=str, default='sep_reset',\n",
    "                    help='dataset file extension')\n",
    "parser.add_argument('--scale', type=int, default=4,\n",
    "                    help='super resolution scale')\n",
    "parser.add_argument('--patch_size', type=int, default=192,\n",
    "                    help='output patch size')\n",
    "parser.add_argument('--rgb_range', type=int, default=255,\n",
    "                    help='maximum value of RGB')\n",
    "parser.add_argument('--n_colors', type=int, default=3,\n",
    "                    help='number of color channels to use')\n",
    "parser.add_argument('--noise', type=str, default='.',\n",
    "                    help='Gaussian noise std.')\n",
    "parser.add_argument('--chop', action='store_true',\n",
    "                    help='enable memory-efficient forward')\n",
    "\n",
    "# Model specifications\n",
    "parser.add_argument('--model', default='RCAN',\n",
    "                    help='model name')\n",
    "\n",
    "parser.add_argument('--act', type=str, default='relu',\n",
    "                    help='activation function')\n",
    "parser.add_argument('--pre_train', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "parser.add_argument('--extend', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "parser.add_argument('--n_resblocks', type=int, default=20,\n",
    "                    help='number of residual blocks')\n",
    "parser.add_argument('--n_feats', type=int, default=64,\n",
    "                    help='number of feature maps')\n",
    "parser.add_argument('--res_scale', type=float, default=1,\n",
    "                    help='residual scaling')\n",
    "parser.add_argument('--shift_mean', default=True,\n",
    "                    help='subtract pixel mean from the input')\n",
    "parser.add_argument('--precision', type=str, default='single',\n",
    "                    choices=('single', 'half'),\n",
    "                    help='FP precision for test (single | half)')\n",
    "\n",
    "# Training specifications\n",
    "parser.add_argument('--reset', action='store_true',\n",
    "                    help='reset the training')\n",
    "parser.add_argument('--test_every', type=int, default=1000,\n",
    "                    help='do test per every N batches')\n",
    "parser.add_argument('--epochs', type=int, default=1000,\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='input batch size for training')\n",
    "parser.add_argument('--split_batch', type=int, default=1,\n",
    "                    help='split the batch into smaller chunks')\n",
    "parser.add_argument('--self_ensemble', action='store_true',\n",
    "                    help='use self-ensemble method for test')\n",
    "parser.add_argument('--test_only', action='store_true',\n",
    "                    help='set this option to test the model')\n",
    "parser.add_argument('--gan_k', type=int, default=1,\n",
    "                    help='k value for adversarial loss')\n",
    "\n",
    "# Optimization specifications\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay', type=int, default=200,\n",
    "                    help='learning rate decay per N epochs')\n",
    "parser.add_argument('--decay_type', type=str, default='step',\n",
    "                    help='learning rate decay type')\n",
    "parser.add_argument('--gamma', type=float, default=0.5,\n",
    "                    help='learning rate decay factor for step decay')\n",
    "parser.add_argument('--optimizer', default='ADAM',\n",
    "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
    "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--beta1', type=float, default=0.9,\n",
    "                    help='ADAM beta1')\n",
    "parser.add_argument('--beta2', type=float, default=0.999,\n",
    "                    help='ADAM beta2')\n",
    "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
    "                    help='ADAM epsilon for numerical stability')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "\n",
    "# Loss specifications\n",
    "parser.add_argument('--loss', type=str, default='1*L1',\n",
    "                    help='loss function configuration')\n",
    "parser.add_argument('--skip_threshold', type=float, default='1e6',\n",
    "                    help='skipping batch that has large error')\n",
    "\n",
    "# Log specifications\n",
    "parser.add_argument('--save', type=str, default='test',\n",
    "                    help='file name to save')\n",
    "parser.add_argument('--load', type=str, default='.',\n",
    "                    help='file name to load')\n",
    "parser.add_argument('--resume', type=int, default=0,\n",
    "                    help='resume from specific checkpoint')\n",
    "parser.add_argument('--print_model', action='store_true',\n",
    "                    help='print model')\n",
    "parser.add_argument('--save_models', action='store_true',\n",
    "                    help='save all intermediate models')\n",
    "parser.add_argument('--print_every', type=int, default=100,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_results', action='store_true',\n",
    "                    help='save output results')\n",
    "\n",
    "# options for residual group and feature channel reduction\n",
    "parser.add_argument('--n_resgroups', type=int, default=10,\n",
    "                    help='number of residual groups')\n",
    "parser.add_argument('--reduction', type=int, default=16,\n",
    "                    help='number of feature maps reduction')\n",
    "# options for test\n",
    "parser.add_argument('--testpath', type=str, default='../test/DIV2K_val_LR_our',\n",
    "                    help='dataset directory for testing')\n",
    "parser.add_argument('--testset', type=str, default='Set5',\n",
    "                    help='dataset name for testing')\n",
    "\n",
    "args = parser.parse_args()\n",
    "template.set_template(args)\n",
    "\n",
    "args.dir_train = list(map(lambda x: x, args.dir_train.split('+')))\n",
    "args.dir_test = list(map(lambda x: x, args.dir_train.split('+')))\n",
    "\n",
    "if args.epochs == 0:\n",
    "    args.epochs = 1e8\n",
    "\n",
    "for arg in vars(args):\n",
    "    if vars(args)[arg] == 'True':\n",
    "        vars(args)[arg] = True\n",
    "    elif vars(args)[arg] == 'False':\n",
    "        vars(args)[arg] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "checkpoint = utility.checkpoint(args)\n",
    "\n",
    "if checkpoint.ok:\n",
    "    train_loader = data.DS(args.dir_train, crop_size=args.patch_size * args.scale, upscale_factor=args.scale)\n",
    "    test_loader = data.DS(args.dir_test, crop_size=args.patch_size * args.scale, upscale_factor=args.scale)\n",
    "\n",
    "    model = model.Model(args, checkpoint)\n",
    "    loss = loss.Loss(args, checkpoint) if not args.test_only else None\n",
    "    t = Trainer(args, train_loader, test_loader, model, loss, checkpoint)\n",
    "    while not t.terminate():\n",
    "        t.train()\n",
    "        t.test()\n",
    "\n",
    "    checkpoint.done()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
